{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid , save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Nietzche Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.io import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='../data/nietzsche/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "get_data(\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\", f'{PATH}nietzsche.txt')\n",
    "text = open(f'{PATH}nietzsche.txt').read()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREFACE\\n\\n\\nSUPPOSING that Truth is a woman--what then? Is there not ground\\nfor suspecting that all philosophers, in so far as they have been\\ndogmatists, have failed to understand women--that the terrible\\nseriousness and clumsy importunity with which they have usually paid\\ntheir addresses to Truth, have been unskilled and unseemly methods for\\nwinning a woman? Certainly she has never allowed herself '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 85\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n !\"\\'(),-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxy'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars.insert(0, \"\\0\")\n",
    "\n",
    "''.join(chars[1:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = {c: i for i, c in enumerate(chars)}\n",
    "indices_char = {i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 42, 29, 30, 25, 27, 29, 1, 1, 1]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = [char_indices[c] for c in text]\n",
    "\n",
    "idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREFACE\\n\\n\\nSUPPOSING that Truth is a woman--what then? Is there not gro'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in idx[:70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx2char(idx):\n",
    "    return ''.join(indices_char[i] for i in idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(a,c): \n",
    "    return np.eye(c)[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, text, idx, vocab_size, timesteps):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.text = text\n",
    "        self.dataset = idx\n",
    "        self.data_length = len(idx)\n",
    "        self.timesteps = timesteps\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.data_length // self.timesteps)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx*self.timesteps\n",
    "        x = self.dataset[start:start+self.timesteps]\n",
    "        y = self.dataset[start+1:start+self.timesteps+1]\n",
    "        return one_hot(x, vocab_size), np.array(y)\n",
    "#         return np.array(x), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "timesteps = 64\n",
    "md = TextDataset(text, idx, vocab_size, timesteps)\n",
    "# md = MusicDataset(h5_file='concat_corpus.h5', set_type='train', json_file='concat_corpus.json', timesteps=timesteps, root_dir=CONCAT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(md,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset sanity test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = enumerate(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, (x, y) = next(train_iter)\n",
    "i2, (x2, y2) = next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 42, 29, 30, 25, 27, 29, 1, 1, 1]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREFACE\\n\\n\\n'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2char(md.dataset[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     1  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "       ...          ⋱          ...       \n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "[torch.DoubleTensor of size 64x85]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\n    0     0     0  ...      0     0     0\n    0     0     1  ...      0     0     0\n    0     0     0  ...      0     0     0\n       ...          ⋱          ...       \n    0     0     0  ...      0     0     0\n    0     0     0  ...      0     0     0\n    0     0     0  ...      0     0     0\n[torch.DoubleTensor of size 64x85]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-ac022cd9f602>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midx2char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-133-793aec7763bf>\u001b[0m in \u001b[0;36midx2char\u001b[0;34m(idx)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0midx2char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-133-793aec7763bf>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0midx2char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: \n    0     0     0  ...      0     0     0\n    0     0     1  ...      0     0     0\n    0     0     0  ...      0     0     0\n       ...          ⋱          ...       \n    0     0     0  ...      0     0     0\n    0     0     0  ...      0     0     0\n    0     0     0  ...      0     0     0\n[torch.DoubleTensor of size 64x85]\n"
     ]
    }
   ],
   "source": [
    "idx2char(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_enabled = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repackage_var(h):\n",
    "    \"\"\"Wraps h in new Variables, to detach them from their history.\"\"\"\n",
    "    if type(h) == torch.autograd.Variable:\n",
    "        v = torch.autograd.Variable(h.data)\n",
    "        return v.cuda() if cuda_enabled else v\n",
    "    else:\n",
    "        return tuple(repackage_var(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatefulLSTM(torch.nn.Module):\n",
    "    def __init__(self, scale_size, n_hidden, n_factors, bs, nl):\n",
    "        super().__init__()\n",
    "        self.scale_size = scale_size\n",
    "        self.nl = nl\n",
    "        self.embedding = torch.nn.Embedding(scale_size, n_factors)\n",
    "        \n",
    "        self.rnn1 = torch.nn.LSTM(n_factors, n_hidden, nl, dropout=0.5, batch_first=True)\n",
    "        self.rnn2 = torch.nn.LSTM(n_hidden, n_hidden, nl, dropout=0.5, batch_first=True)\n",
    "        self.rnn3 = torch.nn.LSTM(n_hidden, n_hidden, nl, dropout=0.5, batch_first=True)\n",
    "        \n",
    "        if cuda_enabled:\n",
    "            self.rnn1 = self.rnn1.cuda()\n",
    "            self.rnn2 = self.rnn2.cuda()\n",
    "            self.rnn3 = self.rnn3.cuda()\n",
    "        \n",
    "#         self.bn1 = nn.utils.weight_norm(self.rnn1, 'weight_hh_l0')\n",
    "#         self.bn1 = nn.utils.weight_norm(self.bn1, 'weight_ih_l0')\n",
    "#         self.bn2 = nn.utils.weight_norm(self.rnn2, 'weight_hh_l0')\n",
    "#         self.bn2 = nn.utils.weight_norm(self.bn2, 'weight_ih_l0')\n",
    "#         self.bn3 = nn.utils.weight_norm(self.rnn3, 'weight_hh_l0')\n",
    "#         self.bn3 = nn.utils.weight_norm(self.bn3, 'weight_ih_l0')\n",
    "        \n",
    "        # pytorch rnn does not currently work with batchnorm\n",
    "        self.l_out = torch.nn.Linear(n_hidden, scale_size)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.reset_all_hidden(bs)\n",
    "        self.bs = bs\n",
    "        \n",
    "    def forward(self, notes):\n",
    "        bs = notes.shape[0]\n",
    "        if self.h1[0].size(1) != bs: \n",
    "            self.reset_all_hidden(bs)\n",
    "        emb = self.embedding(notes)\n",
    "        outp1,h1 = self.rnn1(emb, self.h1)\n",
    "#         outp2,h2 = self.bn2(outp1, self.h2)\n",
    "#         outp3,h3 = self.bn3(outp2, self.h3)\n",
    "        self.h1 = repackage_var(h1)\n",
    "#         self.h2 = repackage_var(h2)\n",
    "#         self.h3 = repackage_var(h3)\n",
    "        return torch.nn.functional.log_softmax(self.l_out(outp1), dim=-1).view(-1, self.scale_size)\n",
    "#         return torch.nn.functional.log_softmax(self.l_out(outp[:, -1, :]), dim=-1)\n",
    "#         return torch.nn.functional.softmax(self.l_out(outp[:, -1, :]), dim=-1)\n",
    "    \n",
    "    def reset_all_hidden(self, bs):\n",
    "        self.h1 = self.init_hidden(bs)\n",
    "        self.h2 = self.init_hidden(bs)\n",
    "        self.h3 = self.init_hidden(bs)\n",
    "        \n",
    "    def init_hidden(self, bs):\n",
    "        h1 = torch.autograd.Variable(torch.zeros(self.nl, bs, self.n_hidden))\n",
    "        h2 = torch.autograd.Variable(torch.zeros(self.nl, bs, self.n_hidden))\n",
    "        if cuda_enabled:\n",
    "            return (h1.cuda(), h2.cuda())\n",
    "        return h1, h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatefulLSTM(torch.nn.Module):\n",
    "    def __init__(self, scale_size, n_hidden, n_factors, bs, nl):\n",
    "        super().__init__()\n",
    "        self.scale_size = scale_size\n",
    "        self.nl = nl\n",
    "#         self.embedding = torch.nn.Embedding(scale_size, n_factors)\n",
    "        \n",
    "        self.rnn1 = torch.nn.LSTM(scale_size, n_hidden, nl, dropout=0.5, batch_first=True)\n",
    "        self.rnn2 = torch.nn.LSTM(n_hidden, n_hidden, nl, dropout=0.5, batch_first=True)\n",
    "        self.rnn3 = torch.nn.LSTM(n_hidden, n_hidden, nl, dropout=0.5, batch_first=True)\n",
    "        \n",
    "        if cuda_enabled:\n",
    "            self.rnn1 = self.rnn1.cuda()\n",
    "            self.rnn2 = self.rnn2.cuda()\n",
    "            self.rnn3 = self.rnn3.cuda()\n",
    "        \n",
    "#         self.bn1 = nn.utils.weight_norm(self.rnn1, 'weight_hh_l0')\n",
    "#         self.bn1 = nn.utils.weight_norm(self.bn1, 'weight_ih_l0')\n",
    "#         self.bn2 = nn.utils.weight_norm(self.rnn2, 'weight_hh_l0')\n",
    "#         self.bn2 = nn.utils.weight_norm(self.bn2, 'weight_ih_l0')\n",
    "#         self.bn3 = nn.utils.weight_norm(self.rnn3, 'weight_hh_l0')\n",
    "#         self.bn3 = nn.utils.weight_norm(self.bn3, 'weight_ih_l0')\n",
    "        \n",
    "        # pytorch rnn does not currently work with batchnorm\n",
    "        self.l_out = torch.nn.Linear(n_hidden, scale_size)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.reset_all_hidden(bs)\n",
    "        self.bs = bs\n",
    "        \n",
    "    def forward(self, notes):\n",
    "        bs = notes.shape[0]\n",
    "        if self.h1[0].size(1) != bs: \n",
    "            self.reset_all_hidden(bs)\n",
    "#         emb = self.embedding(notes)\n",
    "        outp1,h1 = self.rnn1(notes, self.h1)\n",
    "#         outp2,h2 = self.bn2(outp1, self.h2)\n",
    "#         outp3,h3 = self.bn3(outp2, self.h3)\n",
    "        self.h1 = repackage_var(h1)\n",
    "#         self.h2 = repackage_var(h2)\n",
    "#         self.h3 = repackage_var(h3)\n",
    "        return torch.nn.functional.log_softmax(self.l_out(outp1), dim=-1).view(-1, self.scale_size)\n",
    "#         return torch.nn.functional.log_softmax(self.l_out(outp[:, -1, :]), dim=-1)\n",
    "#         return torch.nn.functional.softmax(self.l_out(outp[:, -1, :]), dim=-1)\n",
    "    \n",
    "    def reset_all_hidden(self, bs):\n",
    "        self.h1 = self.init_hidden(bs)\n",
    "        self.h2 = self.init_hidden(bs)\n",
    "        self.h3 = self.init_hidden(bs)\n",
    "        \n",
    "    def init_hidden(self, bs):\n",
    "        h1 = torch.autograd.Variable(torch.zeros(self.nl, bs, self.n_hidden))\n",
    "        h2 = torch.autograd.Variable(torch.zeros(self.nl, bs, self.n_hidden))\n",
    "        if cuda_enabled:\n",
    "            return (h1.cuda(), h2.cuda())\n",
    "        return h1, h2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = StatefulLSTM(md.vocab_size, n_hidden=256, n_factors=2, bs=batch_size, nl=2)\n",
    "if cuda_enabled:\n",
    "    m = m.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = torch.optim.Adam(m.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100 Loss: 3.100971221923828\n",
      "Step: 0 Loss: 6.7294697761535645\n",
      "Iteration: 100 Loss: 2.9367051124572754\n",
      "Step: 1 Loss: 4.379326343536377\n",
      "Iteration: 100 Loss: 2.871424674987793\n",
      "Step: 2 Loss: 2.55930495262146\n",
      "Iteration: 100 Loss: 2.4127304553985596\n",
      "Step: 3 Loss: 2.2250146865844727\n",
      "Iteration: 100 Loss: 2.1682047843933105\n",
      "Step: 4 Loss: 2.0256271362304688\n",
      "Iteration: 100 Loss: 2.02180552482605\n",
      "Step: 5 Loss: 1.8907009363174438\n",
      "Iteration: 100 Loss: 1.8985837697982788\n",
      "Step: 6 Loss: 1.7914042472839355\n",
      "Iteration: 100 Loss: 1.7919671535491943\n",
      "Step: 7 Loss: 1.694566011428833\n",
      "Iteration: 100 Loss: 1.7399513721466064\n",
      "Step: 8 Loss: 1.6267189979553223\n",
      "Iteration: 100 Loss: 1.6889568567276\n",
      "Step: 9 Loss: 1.5837594270706177\n",
      "Iteration: 100 Loss: 1.6574040651321411\n",
      "Step: 10 Loss: 1.5568667650222778\n",
      "Iteration: 100 Loss: 1.6221787929534912\n",
      "Step: 11 Loss: 1.5133399963378906\n",
      "Iteration: 100 Loss: 1.5999693870544434\n",
      "Step: 12 Loss: 1.4856986999511719\n",
      "Iteration: 100 Loss: 1.5745209455490112\n",
      "Step: 13 Loss: 1.43955659866333\n",
      "Iteration: 100 Loss: 1.5543262958526611\n",
      "Step: 14 Loss: 1.4331148862838745\n",
      "Iteration: 100 Loss: 1.5340224504470825\n",
      "Step: 15 Loss: 1.4077900648117065\n",
      "Iteration: 100 Loss: 1.5235724449157715\n",
      "Step: 16 Loss: 1.387189507484436\n",
      "Iteration: 100 Loss: 1.5090910196304321\n",
      "Step: 17 Loss: 1.3719308376312256\n",
      "Iteration: 100 Loss: 1.497626781463623\n",
      "Step: 18 Loss: 1.3555347919464111\n",
      "Iteration: 100 Loss: 1.47257661819458\n",
      "Step: 19 Loss: 1.3431986570358276\n"
     ]
    }
   ],
   "source": [
    "display_step = 100\n",
    "training_steps = 20\n",
    "for step in range(training_steps):\n",
    "# for step in tqdm(range(training_steps)):\n",
    "    for i, (data,target) in enumerate(train_loader):\n",
    "        data, target = torch.autograd.Variable(data.float()), torch.autograd.Variable(target.long())\n",
    "        if cuda_enabled:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        m.zero_grad()\n",
    "        forward = m(data)\n",
    "        loss = loss_fn(forward, target.view(-1))\n",
    "        loss.backward()\n",
    "        train_op.step()\n",
    "        if ((i+1) % display_step == 0):\n",
    "            print(f'Iteration: {i+1} Loss: {loss.data[0]}')\n",
    "    print(f'Step: {step} Loss: {loss.data[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100 Loss: 1.7637908458709717\n",
      "Step: 0 Loss: 1.6685713529586792\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-2c176f98e9ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mforward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-03f4a3bbbd4c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, notes)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnotes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_all_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0moutp1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-03f4a3bbbd4c>\u001b[0m in \u001b[0;36mreset_all_hidden\u001b[0;34m(self, bs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_all_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-03f4a3bbbd4c>\u001b[0m in \u001b[0;36minit_hidden\u001b[0;34m(self, bs)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mh2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcuda_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCudaTransfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, device, async)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "display_step = 100\n",
    "training_steps = 20\n",
    "for step in range(training_steps):\n",
    "# for step in tqdm(range(training_steps)):\n",
    "    for i, (data,target) in enumerate(train_loader):\n",
    "        data, target = torch.autograd.Variable(data.long()), torch.autograd.Variable(target.long())\n",
    "        if cuda_enabled:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        m.zero_grad()\n",
    "        forward = m(data)\n",
    "        loss = loss_fn(forward, target.view(-1))\n",
    "        loss.backward()\n",
    "        train_op.step()\n",
    "        if ((i+1) % display_step == 0):\n",
    "            print(f'Iteration: {i+1} Loss: {loss.data[0]}')\n",
    "    print(f'Step: {step} Loss: {loss.data[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_idxs = generate_sequence(song_seed, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'{OUT_DIR}/../models/nietzsche_stackedlstm_rnn_t64.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(m.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda_enabled:\n",
    "    m.load_state_dict(torch.load(model_path))\n",
    "else:\n",
    "    m.load_state_dict(torch.load(model_path, map_location=lambda storage, loc: storage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate music"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to have unknown state 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = md.timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.arange(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(song, seq_length):\n",
    "    full_song = song.tolist()\n",
    "    # generate music!\n",
    "#     m.reset_all_hidden(batch_size)\n",
    "    for i in range(seq_length):\n",
    "#         seed = np.array([full_song[-timesteps:]])\n",
    "        seed = np.array([one_hot(full_song[-timesteps:], vocab_size)])\n",
    "#         print(''.join(indices_char[i] for i in full_song[-timesteps:]))\n",
    "        # Use our RNN for prediction using our seed! \n",
    "        seed_v = torch.autograd.Variable(torch.from_numpy(seed).float())\n",
    "        if cuda_enabled:\n",
    "            seed_v = seed_v.cuda()\n",
    "        predict_probs = m(seed_v)\n",
    "\n",
    "        # Define output vector for our generated song by sampling from our predicted probability distribution        \n",
    "        sampled_note = torch.multinomial(predict_probs[-1].exp(), 1).data[0]\n",
    "#         print('Sampled_note:', sampled_note)\n",
    "        full_song.append(sampled_note)\n",
    "        \n",
    "        # With multi output model, use only the last prediction. As it is predicting to n timesteps\n",
    "#         v, idx = torch.max(torch.exp(predict_probs[-1]), 0)\n",
    "#         print(idx)\n",
    "#         full_song.append(idx.data[0])\n",
    "    return full_song\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_idxs = generate_sequence(np.array(song_seed), 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hopenhauer, under the dominion and delusion of\\nmorality,--whoever in ard one\\'s astemption the matter of\\nthe too\\nmodelon!=--Their wire himself. As example and some camoring unavounce All little chanced experiences\\nwith itself, that the other as it is\\nthe\\nliveness\"\\nof the our expise of deligitary morashy in sociom.=--The appearf as upon it him\\nwithin an atquined more man would not mather these kind in one\\'s belienity of thereby proof analy in\\nEncoded\\nof his emotion to the heavinaves and impursicnes of Right and\\nblind responssible and bath from this necessary,\\n'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2char(gen_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_input(partial):\n",
    "    _, _, _, seq = partial\n",
    "    input = seq[-timesteps:]\n",
    "    input_var = torch.autograd.Variable(torch.LongTensor([input]))\n",
    "    if cuda_enabled:\n",
    "        input_var = input_var.cuda()\n",
    "    return input_var\n",
    "\n",
    "# song = string\n",
    "# seq_length = generated song length\n",
    "# beam_size = what to choose from\n",
    "def beam_search(song, seq_length, beam_size):    \n",
    "    full_song = song.tolist()\n",
    "    m.reset_all_hidden(batch_size)\n",
    "    partial_sequences = [(0, 0, [], full_song)]\n",
    "    m.eval()\n",
    "\n",
    "    for i in range(seq_length):\n",
    "        partial_sequences = find_partials(partial_sequences, beam_size)\n",
    "        \n",
    "    final_sequence = partial_sequences[0][3]\n",
    "    return final_sequence\n",
    "    \n",
    "def find_partials(partial_sequences, beam_size):\n",
    "    partial_next = []\n",
    "    for partial in partial_sequences:\n",
    "        it, tot_p, p_list, seq = partial\n",
    "        x_input = get_x_input(partial)\n",
    "\n",
    "        predict_probs = m(x_input)\n",
    "        # last_it_probs = torch.exp(predict_probs[-(it+1):]) # this is to predict the last few iterations\n",
    "        last_it_probs = torch.exp(predict_probs[-1:])\n",
    "        top, idxs = torch.topk(last_it_probs, beam_size, 1)\n",
    "\n",
    "        for i in range(beam_size):\n",
    "            prob = top.data[0][i]\n",
    "            idx = idxs.data[0][i]\n",
    "            new_p_list = p_list+[prob]\n",
    "            partial_next.append((it+1, np.mean(new_p_list), new_p_list, seq+[idx]))\n",
    "\n",
    "    partial_sequences = sorted(partial_next, key=lambda x: x[1], reverse=True)[:3]\n",
    "    return partial_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_choice(top, idxs):\n",
    "    return np.random.choice(\n",
    "      idxs.data.numpy().reshape(-1), \n",
    "      1,\n",
    "      p=(top/top.sum()).data.numpy().reshape(-1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153093"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = random.randint(0, len(md.dataset)//2)\n",
    "song_seed = md.dataset[random_seed:random_seed+md.timesteps]\n",
    "# generated_idxs = generate_sequence(song_seed, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hopenhauer, under the dominion and delusion of\\nmorality,--whoeve'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in song_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_gen_idxs = beam_search(np.array(song_seed), 500, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_idxs = generate_sequence(np.array(song_seed), 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hopenhauer, under the dominion and delusion of\\nmorality,--whoever the '"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2char(gen_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hopenhauer, under the dominion and delusion of\\nmorality,--whoever, tha'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2char(bs_gen_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam search end - Decoding time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_output(output_idx):\n",
    "    idx2token = md.concat_json['idx_to_token']\n",
    "    token_list = list(map(lambda x: idx2token.get(str(x), ''), output_idx))\n",
    "    return decode_token(token_list)\n",
    "\n",
    "def decode_token(token_list):\n",
    "    if (token_list[0] != START_DELIM):\n",
    "        token_list.insert(0, START_DELIM)\n",
    "    token_str = ''.join(token_list)\n",
    "    with open(f'{SCRATCH_DIR}/utf_to_txt.json', 'r') as f:\n",
    "        utf_to_txt = json.load(f)\n",
    "    score, stream = decode.decode_string(utf_to_txt, token_str)\n",
    "    return token_str, score, stream\n",
    "\n",
    "# test = [idx2token[f'{x}'] for x in seq_arr]; test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_seed = md.dataset[:md.timesteps]\n",
    "# generated_idxs = generate_sequence(song_seed, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_gen_idxs = beam_search(np.array(song_seed), 500, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREFACE\\n\\n\\nSUPPOSING that Truth is a woman--what then? Is there not the present of the present of their in the present of the present of their in the present of the present of their in the present of the present of their in the present of the present of their in the present of the present of their in the present of the present of their in the present of the present of their in the present of the present of their in the present of the present of their in the present of the present of their in the present of the present of their in the present of the sense of t'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in bs_gen_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_idxs = generate_sequence(song_seed, 500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
