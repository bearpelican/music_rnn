{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid , save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old way of pulling out corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{CONCAT_DIR}/concat_corpus.utf') as f:\n",
    "    train_contents = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'їPÿ\\x07{\\x919\\x05)\\x1c'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_contents[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/music/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import h5py    \n",
    "import numpy as np    \n",
    "import json\n",
    "concat_h5 = h5py.File(f'{CONCAT_DIR}/concat_corpus.h5','r+') \n",
    "\n",
    "concat_json = json.load(open(f'{CONCAT_DIR}/concat_corpus.json', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(a,c): \n",
    "    return np.eye(c)[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, h5_file, set_type, json_file, timesteps, root_dir):\n",
    "        self.concat_h5 = h5py.File(f'{root_dir}/{h5_file}','r+')\n",
    "        self.dataset = self.concat_h5[set_type]\n",
    "        self.concat_json = json.load(open(f'{root_dir}/{json_file}', 'rb'))\n",
    "        self.vocab_size = len(self.concat_json['idx_to_token'])+1\n",
    "        self.data_length = self.dataset.shape[0]\n",
    "        self.timesteps = timesteps\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.data_length - self.timesteps)\n",
    "#         return (self.data_length // self.timesteps)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         print(np.arange(10)[0:8]) # example\n",
    "#         print(np.arange(10)[8])\n",
    "        # (AS) Should not have duplicate sequences. \n",
    "        # RBMs do not actually use target value, so no point in repeating next char\n",
    "        x = self.dataset[idx:idx+self.timesteps]\n",
    "        y = self.dataset[idx+self.timesteps]\n",
    "        \n",
    "#         start = idx*self.timesteps\n",
    "#         x = self.dataset[start:start+self.timesteps]\n",
    "#         y = self.dataset[start+self.timesteps]\n",
    "#         x_hot = one_hot(x, self.vocab_size)\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = MusicDataset(h5_file='concat_corpus.h5', set_type='train', json_file='concat_corpus.json', timesteps=20, root_dir=CONCAT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273345"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(md,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS = 6\n",
    "# SOS = location of end of time in 4/4\n",
    "# '6': '\\x91',\n",
    "# '\\x91': '|||',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset sanity test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = enumerate(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, (x, y) = next(train_iter)\n",
    "i2, (x2, y2) = next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10,  6,  6,  6, 11,  3, 12, 13,\n",
       "        6, 14,  8, 15, 16,  6, 14,  8,  4, 16,  6, 14,  8,  9, 16,  6,  2,\n",
       "       17, 18, 19,  6,  7, 20, 21, 22,  6, 23, 20, 21, 22,  6, 24, 20, 21,\n",
       "       22,  6, 25,  3, 26, 27,  6, 28,  8, 29, 30,  6, 23,  8, 29, 30,  6,\n",
       "       24,  8, 29, 30,  6,  2, 17, 18, 31,  6,  7, 20, 21, 32,  6,  7, 20,\n",
       "        4,  5,  6,  7, 20,  9, 10,  6, 23, 26, 12, 18,  6, 24, 29],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.dataset[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.argmax(x[11], axis=1)[:-1]\n",
    "# b = np.argmax(x[10], axis=1)[1:]\n",
    "# np.testing.assert_array_equal(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.argmax(x2[0], axis=1)[:-1]\n",
    "# b = np.argmax(x[-1], axis=1)[1:]\n",
    "# np.testing.assert_array_equal(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, scale_size, n_factors, hidden_size, n_layers=2):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.emb = torch.nn.Embedding(scale_size, n_factors)\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(n_factors, hidden_size, batch_first=True, \n",
    "                          num_layers=n_layers)\n",
    "#                           bidirectional=True)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        return self.gru(self.emb(input), hidden)\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(inp, encoder):\n",
    "    batch_size, input_length = inp.size()\n",
    "    hidden = encoder.initHidden(batch_size).cuda()\n",
    "    enc_outputs, hidden = encoder(inp, hidden)\n",
    "    return long_t([SOS]*batch_size), enc_outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, scale_size, n_factors, hidden_size, n_layers=2):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.emb = torch.nn.Embedding(scale_size, n_factors)\n",
    "        self.gru = nn.GRU(n_factors, hidden_size, batch_first=True, num_layers=n_layers)\n",
    "        self.out = nn.Linear(hidden_size, scale_size)\n",
    "        \n",
    "    def forward(self, inp, hidden):\n",
    "        emb = self.emb(inp).unsqueeze(1)\n",
    "        res, hidden = self.gru(emb, hidden)\n",
    "        res = F.log_softmax(self.out(res[:,0]), dim=-1)\n",
    "        return res, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Var(*sz): \n",
    "    if len(sz) < 2:\n",
    "        t_k = torch.randn(sz)/np.sqrt(sz[0])\n",
    "    else:\n",
    "        t = torch.zeros(sz)\n",
    "        t_k = torch.nn.init.kaiming_normal(t, a=0, mode='fan_in')\n",
    "    return torch.nn.Parameter(t_k).cuda()\n",
    "\n",
    "def Bias(*sz):\n",
    "    return torch.nn.Parameter(torch.zeros(sz)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, scale_size, n_factors, hidden_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.emb = torch.nn.Embedding(scale_size, n_factors)\n",
    "        self.W1 = Var(hidden_size, hidden_size)\n",
    "        self.W2 = Var(hidden_size, hidden_size)\n",
    "        self.W3 = Var(n_factors+hidden_size, hidden_size)\n",
    "        self.b2 = Bias(hidden_size)\n",
    "        self.b3 = Bias(hidden_size)\n",
    "        self.V = Var(hidden_size)\n",
    "        self.dropout_p = dropout_p\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers=2)\n",
    "        self.out = nn.Linear(hidden_size, scale_size)\n",
    "\n",
    "    def forward(self, inp, hidden, enc_outputs):\n",
    "        emb_inp = self.emb(inp)\n",
    "        emb_inp = self.dropout(emb_inp)\n",
    "#         print('Enc shape:', enc_outputs.shape)\n",
    "#         print('W1 shape:', self.W1.shape)\n",
    "# If encoder is bidirectional, we must double the outputs. See pytorch tutorial\n",
    "        w1e = enc_outputs @ self.W1\n",
    "        w2h = (hidden[-1] @ self.W2 + self.b2).unsqueeze(1)\n",
    "        u = F.tanh(w1e + w2h)\n",
    "        a = (self.V * u).sum(2)\n",
    "        torch.bmm\n",
    "        a = F.softmax(a, dim=-1).unsqueeze(2)\n",
    "        Xa = (a * enc_outputs).sum(1)\n",
    "        res = torch.cat([emb_inp, Xa.squeeze(1)], 1) @ self.W3\n",
    "        res = (res + self.b3).unsqueeze(0)\n",
    "        res, hidden = self.gru(res, hidden)\n",
    "        res = F.log_softmax(self.out(res.squeeze(0)), dim=-1)\n",
    "        return res, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASHAW - deleted target size since we are only predicting 1. See original - deeplearning2 - translate-pytorch.ipynb\n",
    "\n",
    "def train(inp, targ, encoder, decoder, enc_opt, dec_opt, crit):\n",
    "    decoder_input, encoder_outputs, hidden = encode(inp, encoder)\n",
    "    \n",
    "    enc_opt.zero_grad(); dec_opt.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    decoder_output, hidden = decoder(decoder_input, hidden, encoder_outputs)\n",
    "#     decoder_output, hidden = decoder(decoder_input, hidden) # for normal decoder\n",
    "    decoder_input = targ\n",
    "    loss += crit(decoder_output, decoder_input)\n",
    "    \n",
    "    loss.backward()\n",
    "    enc_opt.step(); dec_opt.step()\n",
    "    return loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def req_grad_params(o):\n",
    "    return (p for p in o.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_t(arr): return Variable(torch.LongTensor(arr)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainEpochs(encoder, decoder, n_epochs, print_every=10000, lr=0.001):\n",
    "    loss_total = 0 # Reset every print_every\n",
    "    \n",
    "    enc_opt = optim.RMSprop(req_grad_params(encoder), lr=lr)\n",
    "    dec_opt = optim.RMSprop(decoder.parameters(), lr=lr)\n",
    "    crit = nn.NLLLoss().cuda()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = []\n",
    "        for i, (data,target) in enumerate(train_loader):\n",
    "            inp = torch.autograd.Variable(data.long().cuda())\n",
    "            targ = torch.autograd.Variable(target.long().cuda())\n",
    "            \n",
    "            loss = train(inp, targ, encoder, decoder, enc_opt, dec_opt, crit)\n",
    "            loss_total += loss\n",
    "            epoch_loss.append(loss)\n",
    "            \n",
    "            if i % print_every == print_every-1:\n",
    "                print(f'Iteration {i+1}. Loss: {loss_total / print_every}')\n",
    "                loss_total = 0\n",
    "\n",
    "        print(f'Epoch {epoch}. Loss:', np.mean(epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "encoder = EncoderRNN(md.vocab_size, n_factors=12, hidden_size=hidden_size).cuda()\n",
    "decoder = AttnDecoderRNN(md.vocab_size, n_factors=12, hidden_size=hidden_size).cuda()\n",
    "# decoder = AttnDecoderRNN_P(en_emb_t, hidden_size).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 300 loss: 0.8163380514085293\n",
      "iteration 600 loss: 0.7554223091651996\n",
      "iteration 900 loss: 0.7045671861618757\n",
      "iteration 1200 loss: 0.8490692144632339\n",
      "iteration 1500 loss: 0.7600323867797851\n",
      "iteration 1800 loss: 0.8027548969785372\n",
      "iteration 2100 loss: 0.6801020619273186\n",
      "iteration 2400 loss: 0.766221761306127\n",
      "iteration 2700 loss: 0.7849357808132966\n",
      "iteration 3000 loss: 0.7168189486612876\n",
      "iteration 3300 loss: 0.7011970803141594\n",
      "iteration 3600 loss: 0.8384964121381442\n",
      "iteration 3900 loss: 0.7792342467109362\n",
      "iteration 4200 loss: 0.8187494166692098\n",
      "Epoch 0 loss: 0.7681482396165279\n",
      "iteration 300 loss: 0.8528565761446952\n",
      "iteration 600 loss: 0.7590376927951972\n",
      "iteration 900 loss: 0.7186621319254239\n",
      "iteration 1200 loss: 0.8776449112097422\n",
      "iteration 1500 loss: 0.7792076162497202\n",
      "iteration 1800 loss: 0.7977067322532336\n",
      "iteration 2100 loss: 0.679408333748579\n",
      "iteration 2400 loss: 0.7737932443618775\n",
      "iteration 2700 loss: 0.8087839002907277\n",
      "iteration 3000 loss: 0.7427827994773786\n",
      "iteration 3300 loss: 0.7200889501472314\n",
      "iteration 3600 loss: 0.8429973411063353\n",
      "iteration 3900 loss: 0.7743257920940717\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-11b49afccdb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainEpochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-139-140122431add>\u001b[0m in \u001b[0;36mtrainEpochs\u001b[0;34m(encoder, decoder, n_epochs, print_every, lr)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mtarg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mloss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mepoch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-136-1cf0e3de0288>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(inp, targ, encoder, decoder, enc_opt, dec_opt, crit)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0menc_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mdec_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-125-ca2c80466982>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(inp, encoder)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0menc_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlong_t\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSOS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-124-d2385216fcbe>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         )\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhack_onnx_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.6/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36m_do_forward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mflat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iter_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mflat_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNestedIOFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mnested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mnested_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.6/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mnested_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_variable_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward_extended\u001b[0;34m(self, input, weight, hx)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.6/site-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(fn, input, hx, weight, output, hy)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_descs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_descs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhx_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhy_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcx_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.6/site-packages/torch/backends/cudnn/__init__.py\u001b[0m in \u001b[0;36mdescriptor\u001b[0;34m(tensor, N)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mdescriptor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDescriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mdescriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdescriptor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.6/site-packages/torch/backends/cudnn/__init__.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainEpochs(encoder, decoder, 5, print_every=300, lr=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing encoder-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp):\n",
    "    inp = torch.autograd.Variable(torch.Tensor(inp.reshape(1, -1))).long().cuda()\n",
    "    decoder_input, encoder_outputs, hidden = encode(inp, encoder)\n",
    "    target_length = maxlen\n",
    "\n",
    "    decoded_words = []\n",
    "    for di in range(target_length):\n",
    "#         decoder_output, hidden = decoder(decoder_input, hidden)\n",
    "        decoder_output, hidden = decoder(decoder_input, hidden, encoder_outputs)\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        decoded_words.append(ni)\n",
    "        decoder_input = long_t([ni])\n",
    "    \n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate music"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to change sequence_length to timesteps  \n",
    "Need to have unknown state 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_output(output_idx):\n",
    "    idx2token = md.concat_json['idx_to_token']\n",
    "    token_list = list(map(lambda x: idx2token.get(str(x), ''), output_idx))\n",
    "    return decode_token(token_list)\n",
    "\n",
    "def decode_token(token_list):\n",
    "    if (token_list[0] != START_DELIM):\n",
    "        token_list.insert(0, START_DELIM)\n",
    "    token_str = ''.join(token_list)\n",
    "    with open(f'{SCRATCH_DIR}/utf_to_txt.json', 'r') as f:\n",
    "        utf_to_txt = json.load(f)\n",
    "    score, stream = decode.decode_string(utf_to_txt, token_str)\n",
    "    return token_str, score, stream\n",
    "\n",
    "# test = [idx2token[f'{x}'] for x in seq_arr]; test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_song = md.dataset[:md.timesteps]\n",
    "decoded_words = evaluate(gen_song)\n",
    "output_song = gen_song.tolist() + decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_str, score, stream = decode_output(decoded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'їÐÐÐÐÐÐÐÐÐÐÐÐææææÐÐæÐæÐÐÐ\\x91Ð\\x91Ð\\x91Ð\\x91Ð\\x91Ð\\x91ÐÐæÐÐ\\x91\\x91\\x91\\x91\\x91\\x91ææÐæææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææææ'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For testing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{SCRATCH_DIR}/utf_to_txt.json', 'r') as f:\n",
    "    utf_to_txt = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str = train_contents[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str = open(f'{SCRATCH_DIR}/BWV-400-nomask-fermatas.utf', 'r').read()[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_str, score, stream = decode_token(test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.elements[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 49,
       "width": 748
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = stream.write('midi', fp=f'{OUT_DIR}/testout.midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = stream.write('xml', fp=f'{OUT_DIR}/testout.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.lib.display import FileLink\n",
    "FileLink('../data/bachbot/out/testout.midi')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
