{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from util.midi_manipulation import noteStateMatrixToMidi, midiToNoteStateMatrix, lowerBound, upperBound\n",
    "from util.util import print_progress\n",
    "from util.create_dataset import create_dataset, get_batch, make_one_hot_notes\n",
    "\n",
    "import glob\n",
    "import midi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CONCURRENT_NOTES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_onehot(encoded_song):\n",
    "    reversed_encoded = np.zeros((encoded_song.shape[0], MAX_CONCURRENT_NOTES))\n",
    "    for idx, timestamp in enumerate(encoded_song):\n",
    "        note_idxs = np.where(timestamp == 1)[0]\n",
    "        if len(note_idxs) > MAX_CONCURRENT_NOTES:\n",
    "            note_idxs = note_idxs[:MAX_CONCURRENT_NOTES]\n",
    "        reversed_encoded[idx, :len(note_idxs)] = note_idxs\n",
    "    return reversed_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nonhot_dataset(min_length, multi=True):\n",
    "    songs = glob.glob('data/*.mid*')\n",
    "    \n",
    "    encoded_songs = []\n",
    "    discarded = 0\n",
    "    for song in songs:\n",
    "        encoded_song = midiToNoteStateMatrix(song)\n",
    "        if len(encoded_song) >= min_length:\n",
    "            if multi:\n",
    "                encoded_song = reverse_onehot(encoded_song)\n",
    "            else:\n",
    "                encoded_song = make_one_hot_notes(encoded_song)\n",
    "                encoded_song = np.argmax(encoded_song, axis=1)\n",
    "            encoded_songs.append(encoded_song)\n",
    "        else:\n",
    "            discarded += 1\n",
    "    print(\"{} songs processed\".format(len(songs)))\n",
    "    print(\"{} songs discarded\".format(discarded))\n",
    "    return encoded_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 songs processed\n",
      "15 songs discarded\n"
     ]
    }
   ],
   "source": [
    "min_song_length  = 128\n",
    "encoded_songs    = create_nonhot_dataset(min_song_length, multi=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Neural Network Parameters\n",
    "# input_size       = encoded_songs[0].shape[1]   # The number of possible MIDI Notes\n",
    "input_size       = upperBound - lowerBound   # The number of possible MIDI Notes\n",
    "scale_size = input_size # 78\n",
    "output_size      = input_size                  # Same as input size\n",
    "hidden_size      = 256                         # Number of neurons in hidden layer\n",
    "\n",
    "learning_rate    = 0.001 # Learning rate of the model\n",
    "training_steps   = 5000  # Number of batches during training\n",
    "batch_size       = 128    # Number of songs per batch\n",
    "timesteps        = 64    # Length of song snippet -- this is what is fed into the model\n",
    "\n",
    "assert timesteps < min_song_length\n",
    "\n",
    "n_hidden = hidden_size\n",
    "\n",
    "n_factors = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_simult = [np.max(np.sum(song, 1)) for song in encoded_songs]\n",
    "# print(max(max_simult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_songs[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoded_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(encoded_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = glob.glob('data/*.mid*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = midi.read_midifile(songs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_song = midiToNoteStateMatrix(songs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_batch(encoded_songs, batch_size, timesteps, input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_song[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repackage_var(h):\n",
    "    \"\"\"Wraps h in new Variables, to detach them from their history.\"\"\"\n",
    "    return torch.autograd.Variable(h.data).cuda() if type(h) == torch.autograd.Variable else tuple(repackage_var(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatefulLSTM(torch.nn.Module):\n",
    "    def __init__(self, scale_size, n_factors, bs, nl):\n",
    "        super().__init__()\n",
    "        self.scale_size = scale_size\n",
    "        self.nl = nl\n",
    "        self.embedding = torch.nn.Embedding(scale_size, n_factors)\n",
    "        self.rnn = torch.nn.LSTM(n_factors, n_hidden, nl, dropout=0.5)\n",
    "        self.l_out = torch.nn.Linear(n_hidden, scale_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, notes):\n",
    "        bs = notes[0].shape[0]\n",
    "        if self.h[0].size(1) != bs: \n",
    "            print('batch size is not same size as original:', bs)\n",
    "            self.init_hidden(bs)\n",
    "        emb = self.embedding(notes)\n",
    "        outp,h = self.rnn(emb, self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return torch.nn.functional.log_softmax(self.l_out(outp[:, -1, :]), dim=-1)\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        h1 = torch.autograd.Variable(torch.zeros(self.nl, bs, n_hidden))\n",
    "        h2 = torch.autograd.Variable(torch.zeros(self.nl, bs, n_hidden))\n",
    "        if self._cuda():\n",
    "            self.h = (h1.cuda(), h2.cuda())\n",
    "        else:\n",
    "            self.h = (h1, h2)\n",
    "    def _cuda(self):\n",
    "        return next(self.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_enabled = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_batch(encoded_songs, batch_size, timesteps, input_size, output_size):\n",
    "    rand_song_indices = np.random.randint(len(encoded_songs), size=batch_size)\n",
    "#     batch_x = np.zeros((batch_size, timesteps, input_size))\n",
    "    batch_x = np.zeros((batch_size, timesteps, MAX_CONCURRENT_NOTES))\n",
    "    batch_y = np.zeros((batch_size, MAX_CONCURRENT_NOTES))\n",
    "    for i in range(batch_size):\n",
    "        song_ind = rand_song_indices[i]\n",
    "        start_ind = np.random.randint(encoded_songs[song_ind].shape[0]-timesteps-1)\n",
    "        batch_x[i] = encoded_songs[song_ind][start_ind:start_ind+timesteps]\n",
    "        batch_y[i] = encoded_songs[song_ind][start_ind+timesteps]\n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_cuda(*args):\n",
    "    batch_x, batch_y = get_batch(*args)\n",
    "#     y_reverse_hot = batch_y.argmax(axis=1)\n",
    "    y_v = torch.autograd.Variable(torch.from_numpy(batch_y).long())\n",
    "    x_v = torch.autograd.Variable(torch.from_numpy(batch_x).long())\n",
    "    if cuda_enabled:\n",
    "        return x_v.cuda(), y_v.cuda()\n",
    "    return x_v, y_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = StatefulLSTM(scale_size, n_factors, batch_size, 2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_fn = torch.optim.Adam(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss_fn = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing around with batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x, batch_y = get_batch(encoded_songs, batch_size, timesteps, input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17., 33., 36., 41.,  0.],\n",
       "       [24., 36., 40., 43., 50.],\n",
       "       [17., 33., 36., 40.,  0.],\n",
       "       [24., 33., 36., 41.,  0.],\n",
       "       [17., 33., 36., 41., 45.],\n",
       "       [17., 33., 36., 41., 60.],\n",
       "       [19., 36., 38., 43.,  0.],\n",
       "       [17., 33., 36., 41., 43.],\n",
       "       [24., 40., 43.,  0.,  0.],\n",
       "       [19., 35., 36., 38., 43.],\n",
       "       [28., 33., 36., 40.,  0.],\n",
       "       [17., 33., 36., 43.,  0.],\n",
       "       [28., 31., 36., 40., 43.],\n",
       "       [17., 28., 33., 36., 41.],\n",
       "       [24., 36., 40., 43., 50.],\n",
       "       [17., 33., 36., 38., 43.],\n",
       "       [21., 33., 36., 40., 52.],\n",
       "       [19., 35., 38., 43.,  0.],\n",
       "       [24., 36., 40., 41., 43.],\n",
       "       [19., 35., 38., 43.,  0.],\n",
       "       [21., 33., 36., 40.,  0.],\n",
       "       [26., 33., 38., 41., 52.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [21., 33., 36., 40., 52.],\n",
       "       [26., 33., 36., 38., 41.],\n",
       "       [17., 33., 36., 40., 50.],\n",
       "       [17., 33., 36., 41.,  0.],\n",
       "       [21., 33., 36., 40., 52.],\n",
       "       [17., 33., 36., 41., 45.],\n",
       "       [17., 33., 38., 41.,  0.],\n",
       "       [21., 33., 40.,  0.,  0.],\n",
       "       [19., 35., 38., 43.,  0.],\n",
       "       [21., 33., 36., 40.,  0.],\n",
       "       [26., 33., 36., 40., 41.],\n",
       "       [17., 33., 36., 41.,  0.],\n",
       "       [17., 33., 36., 40., 43.],\n",
       "       [24., 36., 40., 43.,  0.],\n",
       "       [21., 33., 36., 40., 52.],\n",
       "       [24., 36., 40.,  0.,  0.],\n",
       "       [19., 35., 38., 43., 45.],\n",
       "       [24., 36., 40., 43.,  0.],\n",
       "       [24., 36., 40., 43., 48.],\n",
       "       [17., 33., 36., 41.,  0.],\n",
       "       [17., 33., 36., 41.,  0.],\n",
       "       [19., 35., 38., 43.,  0.],\n",
       "       [17., 33., 36., 41., 48.],\n",
       "       [19., 28., 35., 38., 43.],\n",
       "       [26., 33., 36., 40., 41.],\n",
       "       [17., 33., 36., 41., 59.],\n",
       "       [28., 35., 40., 43.,  0.],\n",
       "       [24., 29., 36., 40., 43.],\n",
       "       [21., 33., 36., 40., 47.],\n",
       "       [21., 33., 36., 40.,  0.],\n",
       "       [17., 33., 36., 41., 43.],\n",
       "       [21., 33., 36., 40., 43.],\n",
       "       [17., 33., 36., 41.,  0.],\n",
       "       [19., 36., 38., 43.,  0.],\n",
       "       [26., 35., 43.,  0.,  0.],\n",
       "       [28., 33., 36., 40.,  0.],\n",
       "       [17., 33., 41., 43.,  0.],\n",
       "       [21., 33., 36., 40., 43.],\n",
       "       [26., 33., 38., 41.,  0.],\n",
       "       [17., 33., 36., 41., 45.],\n",
       "       [17., 33., 36., 40., 43.],\n",
       "       [28., 33., 36., 40.,  0.],\n",
       "       [22., 34., 38., 41.,  0.],\n",
       "       [28., 33., 36., 40., 45.],\n",
       "       [24., 31., 40., 43.,  0.],\n",
       "       [21., 33., 36., 40., 48.],\n",
       "       [17., 33., 36., 41., 48.],\n",
       "       [28., 35., 40., 43., 48.],\n",
       "       [22., 34., 38., 41.,  0.],\n",
       "       [21., 33., 36., 40., 48.],\n",
       "       [17., 33., 36., 41.,  0.],\n",
       "       [17., 33., 36., 41., 48.],\n",
       "       [17., 33., 36., 40., 41.],\n",
       "       [19., 36., 38., 43.,  0.],\n",
       "       [19., 35., 38., 43.,  0.],\n",
       "       [24., 36., 40., 43., 52.],\n",
       "       [19., 36., 38., 43.,  0.],\n",
       "       [17., 33., 36., 40., 41.],\n",
       "       [17., 33., 36., 41., 52.],\n",
       "       [28., 35., 40., 43.,  0.],\n",
       "       [21., 33., 36., 40.,  0.],\n",
       "       [21., 33., 36., 40.,  0.],\n",
       "       [17., 33., 38., 41., 55.],\n",
       "       [24., 36., 43.,  0.,  0.],\n",
       "       [19., 33., 38., 40., 41.],\n",
       "       [17., 33., 36., 41., 43.],\n",
       "       [26., 33., 36., 41., 43.],\n",
       "       [24., 36., 40., 43., 48.],\n",
       "       [40.,  0.,  0.,  0.,  0.],\n",
       "       [17., 33., 36., 41., 45.],\n",
       "       [19., 31., 35., 38., 43.],\n",
       "       [17., 35., 41., 44.,  0.],\n",
       "       [26., 33., 38., 41., 53.],\n",
       "       [28., 35., 36., 40., 44.],\n",
       "       [17., 33., 36., 41., 48.],\n",
       "       [21., 33., 36., 40., 52.],\n",
       "       [17., 33., 36., 43.,  0.],\n",
       "       [17., 33., 36., 41.,  0.],\n",
       "       [19., 23., 35., 38., 43.],\n",
       "       [24., 36., 38., 40., 43.],\n",
       "       [17., 33., 36., 41.,  0.],\n",
       "       [17., 33., 36., 41.,  0.],\n",
       "       [24., 36., 40.,  0.,  0.],\n",
       "       [19., 35., 38., 43.,  0.],\n",
       "       [21., 33., 36., 40.,  0.],\n",
       "       [17., 33., 36., 38., 41.],\n",
       "       [21., 33., 36., 40., 45.],\n",
       "       [21., 36., 40., 43.,  0.],\n",
       "       [19., 35., 38., 43.,  0.],\n",
       "       [17., 33., 36., 41., 48.],\n",
       "       [17., 33., 36., 40., 41.],\n",
       "       [21., 33., 36., 40., 52.],\n",
       "       [19., 35., 36., 38., 43.],\n",
       "       [22., 34., 38., 41., 43.],\n",
       "       [17., 35., 40., 43.,  0.],\n",
       "       [21., 33., 36., 40., 52.],\n",
       "       [17., 33., 36., 41., 50.],\n",
       "       [17., 32., 35., 36., 41.],\n",
       "       [24., 36., 40., 43., 50.],\n",
       "       [26., 33., 38., 41., 50.],\n",
       "       [24., 36., 40., 43., 55.],\n",
       "       [21., 33., 36., 38., 40.],\n",
       "       [24., 35., 36., 40., 43.],\n",
       "       [17., 33., 36., 41., 45.],\n",
       "       [40.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x, batch_y = get_batch_cuda(encoded_songs, batch_size, timesteps, input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 64, 5])\n",
      "torch.Size([128, 5])\n"
     ]
    }
   ],
   "source": [
    "print(batch_x.shape)\n",
    "print(batch_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-658b37c773a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# vbatch_y = torch.autograd.Variable(torch.from_numpy(y_reverse_hot).long())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mforward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch-upgrade/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-8070dcea2ed7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, notes)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch size is not same size as original:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moutp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepackage_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch-upgrade/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch-upgrade/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch-upgrade/lib/python3.6/site-packages/torch/nn/_functions/thnn/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(cls, ctx, indices, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_input_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Embedding doesn't \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;34m\"compute the gradient w.r.t. the indices\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# vbatch_y = torch.autograd.Variable(torch.from_numpy(y_reverse_hot).long())\n",
    "forward = m(batch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(forward[:, -1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_loss_seq(inp, targ):\n",
    "    sl,bs,nh = inp.size()\n",
    "    targ = targ.transpose(0,1).contiguous().view(-1)\n",
    "    return torch.nn.functional.nll_loss(inp.view(-1,nh), targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(forward, batch_y)\n",
    "loss.backward()\n",
    "optimizer_fn.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??get_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size is not same size as original: 64\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ddf09c8cbd65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#     vbatch_y = torch.autograd.Variable(torch.from_numpy(y_reverse_hot).long())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mforward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch-upgrade/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-8070dcea2ed7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, notes)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch size is not same size as original:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moutp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepackage_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch-upgrade/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch-upgrade/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch-upgrade/lib/python3.6/site-packages/torch/nn/_functions/thnn/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(cls, ctx, indices, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_input_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Embedding doesn't \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;34m\"compute the gradient w.r.t. the indices\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "display_step = 100\n",
    "for step in range(training_steps):\n",
    "# for step in tqdm(range(training_steps)):\n",
    "    batch_x, batch_y = get_batch_cuda(encoded_songs, batch_size, timesteps, input_size, output_size)\n",
    "#     y_reverse_hot = batch_y.argmax(axis=1)\n",
    "#     vbatch_y = torch.autograd.Variable(torch.from_numpy(y_reverse_hot).long())\n",
    "    m.zero_grad()\n",
    "    forward = m(batch_x)\n",
    "    loss = loss_fn(forward, batch_y)\n",
    "    loss.backward()\n",
    "    optimizer_fn.step()\n",
    "    if (step % display_step == 0):\n",
    "        print(f'Step: {step} Loss: {loss.data[0]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m(batch_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Music generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEN_SEED_RANDOMLY = False # Use a random snippet as a seed for generating the new song.\n",
    "if GEN_SEED_RANDOMLY:\n",
    "    ind = np.random.randint(NUM_SONGS)\n",
    "else:\n",
    "    ind = 41 # \"How Deep is Your Love\" by Calvin Harris as a starting seed\n",
    "    \n",
    "gen_song = encoded_songs[ind][:timesteps].tolist() # TODO explore different (non-random) seed options\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(seed):\n",
    "# encoded_songs[ind][:timesteps].tolist()\n",
    "len(gen_song)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We need to have an unknown state (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def noteStateMatrixToMidi(statematrix, name=\"example\", span=scale_size):\n",
    "#     statematrix = np.array(statematrix)\n",
    "    pattern = midi.Pattern()\n",
    "    track = midi.Track()\n",
    "    pattern.append(track)\n",
    "\n",
    "    span = upperBound-lowerBound\n",
    "    tickscale = 55\n",
    "\n",
    "    lastcmdtime = 0\n",
    "    prevstate = 0\n",
    "    for time, state in enumerate(statematrix):  \n",
    "        offNotes = []\n",
    "        onNotes = []\n",
    "        if prevstate != state:\n",
    "            offNotes.append(prevstate)\n",
    "            onNotes.append(state)\n",
    "#         elif state > 0:\n",
    "        prevstate = state\n",
    "        for note in offNotes:\n",
    "            track.append(midi.NoteOffEvent(tick=(time-lastcmdtime)*tickscale, pitch=note+lowerBound))\n",
    "            lastcmdtime = time\n",
    "        for note in onNotes:\n",
    "            track.append(midi.NoteOnEvent(tick=(time-lastcmdtime)*tickscale, velocity=40, pitch=note+lowerBound))\n",
    "            lastcmdtime = time\n",
    "\n",
    "        prevstate = state\n",
    "\n",
    "    eot = midi.EndOfTrackEvent(tick=1)\n",
    "    track.append(eot)\n",
    "\n",
    "    midi.write_midifile(\"{}.mid\".format(name), pattern)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate music!\n",
    "m.init_hidden(batch_size)\n",
    "for i in range(500):\n",
    "    seed = np.array([gen_song[-timesteps:]])\n",
    "    # Use our RNN for prediction using our seed! \n",
    "    '''TODO: Write an expression to use the RNN to get the probability for the next note played based on the seed.\n",
    "    Remember that we are now using the RNN for prediction, not training.'''\n",
    "    # old way\n",
    "    seed_v = torch.autograd.Variable(torch.from_numpy(seed).long()).cuda()\n",
    "\n",
    "#     seed_v = torch.autograd.Variable(torch.from_numpy(np.argmax(seed, axis=1)).long()).cuda()\n",
    "    predict_probs = m(seed_v)\n",
    "    \n",
    "    percentage_prob = (np.e ** predict_probs.data.cpu().numpy())\n",
    "    # Define output vector for our generated song by sampling from our predicted probability distribution\n",
    "    played_notes = np.zeros(output_size)\n",
    "    '''TODO: Sample from the predicted distribution to determine which note gets played next.\n",
    "    You can use a function from the numpy.random library to do this.\n",
    "    Hint 1: range(x) produces a list of all the numbers from 0 to x\n",
    "    Hint 2: make sure what you pass in has the \"shape\" you expect.'''\n",
    "    sampled_note = np.random.choice(range(output_size), p=percentage_prob[0]) # TODO\n",
    "#     print('Sampled_note:', sampled_note)\n",
    "#     played_notes[sampled_note] = 1\n",
    "#     gen_song.append(played_notes)\n",
    "    gen_song.append(sampled_note)\n",
    "\n",
    "noteStateMatrixToMidi(gen_song, name=\"generated/gen_song_0\")\n",
    "noteStateMatrixToMidi(encoded_songs[ind], name=\"generated/base_song_0\")\n",
    "print(\"saved generated song! seed ind: {}\".format(ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.lib.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileLink(\"generated/gen_song_0.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileLink(\"generated/base_song_0.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.array([gen_song[-timesteps:]])\n",
    "#     predict_probs = sess.run(prediction, feed_dict={input_vec: seed}) # TODO\n",
    "seed_v = torch.autograd.Variable(torch.from_numpy(seed).long()).cuda()\n",
    "\n",
    "# seed_v = torch.autograd.Variable(torch.from_numpy(np.argmax(seed, axis=1)).long()).cuda()\n",
    "print(seed_v.size())\n",
    "predict_probs = m(seed_v)\n",
    "\n",
    "print(predict_probs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_probs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(predict_probs.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_prob = (np.e ** predict_probs.data.cpu().numpy())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_note = np.random.choice(range(output_size), p=percentage_prob) # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
